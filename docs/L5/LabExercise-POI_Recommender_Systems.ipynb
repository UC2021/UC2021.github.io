{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CxA59YkI1Y7Y"
   },
   "source": [
    "# Lab2 - Point-of-Interest Recommendation Systems\n",
    "## Urban Computing course - Leiden University\n",
    "#### Instructor: Dr. Mitra Baratchi\n",
    "#### Contributor: Hossein A. Rahmani\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0VWXtk2kFXw"
   },
   "source": [
    "## Outline\n",
    "\n",
    "1.   Recommender systems and Context information\n",
    "2.   General Structure of Location-Based Social Network's Dataset\n",
    "3.   Loading the dataset (Foursquare)\n",
    "4.   Data Pre-processing\n",
    "5.   Matrix Factorization\n",
    "6.   Model Evaluation\n",
    "7.   Utilizing Contextual Information: Geographical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjNJ7x2IGqma"
   },
   "source": [
    "## Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lsl9EwelGuVm"
   },
   "source": [
    "Recommender systems (RSs) aim to predict the most relevant items to a user. RSs are a subclass of **information filtering systems** addressing the problem of information overload. An example of a recommendation system in action is when you visit Youtube website and you notice that some movies are being recommended to you. One of the most important applications of recommender systems is in Location-Based Social Networks (LBSNs) to recommend unvisited Point-of-Interests (POIs) to users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W34USwn7LIP5"
   },
   "source": [
    "### Recommender system approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_0yBRgyLL9L"
   },
   "source": [
    "Recommender System approaches are generally divided into three categories:\n",
    "\n",
    "- **Collaborative Filtering (CF)**: CF methods recommend items to users using their past behavior or their ratings on items, as well as, similar decisions made by other similar users. The CF methods are further divided into two subcategories, __Memory-based__ and __Model-based__. In this lab, we compare two methods selected from each of these two groups.\n",
    "\n",
    "- **Content-Based (CB)**: CB methods recommend items to users using the characteristics (or known features) of an item, aiming to find other items with similar properties.\n",
    "\n",
    "- **Hybrid Method**: A number of applications combine CF and CB algorithms. Using this combinatory approach they aim to overcome the limitations of native CF and CB approaches and improve prediction performance. Importantly, they overcome the CF problems such as sparsity and loss of information. \n",
    "\n",
    "Collaborative filtering is much more popular for recommendations where the data is sparse, i.e., where there is a limited number of interactions by each user or for a particular item.\n",
    "\n",
    "More information for study and comparison can be find in the [Basics of Recommender Systems: Study of Location-Based Social Networks](https://github.com/rahmanidashti/LRSbasics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFi85yAWJMIb"
   },
   "source": [
    "### Context-Aware Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SckvfegaJRfs"
   },
   "source": [
    "In many applications, such as recommending a location, it may not be sufficient to consider only users and items – it is also important to incorporate **contextual information** into the recommendation process in order to recommend items to users in certain time, or location. For example, using the temporal context, a location recommender system would provide a POI recommendation in the afternoon that can be very different from the one in night. In addition, geographical influence is an important contextual factor that distinguishes the location recommendation from traditional item recommendation, because the check-in behavior depends on locations’ geographical features. The users' behavior on location-based social networks shows they would like to visit nearby locations rather than the distant ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kE-1Rm4mcfHs"
   },
   "source": [
    "## LBSN's Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YR1vnRWCbX9X"
   },
   "source": [
    "The dataset of a LBSN is generated based on the feature of registering __Check-in__s. A user can check in a location, to register his/her presence in that location. Generally, a check-in record includes the following:\n",
    "\n",
    "*   UserID\n",
    "*   LocationID\n",
    "*   Latitude and longitude of a location\n",
    "*   Check-in time\n",
    "\n",
    "For example, a record of check-in can be: **user_0, location_0, 1.372494548, 103.893714, 28-01-2019 14:17:15**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bB2JY4SpbPYq"
   },
   "source": [
    "## Import the required module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FM1lNoUdjIzo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import scipy.sparse as sparse\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import multivariate_normal\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# data visualization\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11ln990OclFB"
   },
   "source": [
    "## Load the dataset\n",
    "To access the dataset, we have uploaded the preprocessed dataset of Gowalla [1] LBSN into a Github repository. Here, we have four files that are needed for this assignment: **size, train, test, and geo**. The _size_ file includes the number of users and location (or POIs), _train and test_ files store the user's check-ins and the _geo_ file includes the geographical information of each location. As mentioned above, we load the dataset from Github. This is a small version of Gowalla dataset. You can find other versions (such as Gowalla, Foursquare, or Yelp [1]). Some examples are available in the following repository to evaluate the methods https://github.com/rahmanidashti/LBSNDatasets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7JHBpCu1pqT"
   },
   "outputs": [],
   "source": [
    "size = \"https://raw.githubusercontent.com/rahmanidashti/LBSNDatasets/master/Gowalla/Gowalla_2/Gowalla_data_size.txt\"\n",
    "train = \"https://raw.githubusercontent.com/rahmanidashti/LBSNDatasets/master/Gowalla/Gowalla_2/Gowalla_train.txt\"\n",
    "test = \"https://raw.githubusercontent.com/rahmanidashti/LBSNDatasets/master/Gowalla/Gowalla_2/Gowalla_test.txt\"\n",
    "geo = \"https://raw.githubusercontent.com/rahmanidashti/LBSNDatasets/master/Gowalla/Gowalla_2/Gowalla_poi_coos.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U9zzCJTAM8Pu",
    "outputId": "4263e86b-0650-4bd2-e727-d230cfeb417e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numebr of users is 100 and the number of locations is 6436\n"
     ]
    }
   ],
   "source": [
    "\"\"\" read the datasets as CSV files \"\"\"\n",
    "\n",
    "size_header = ['users', 'locations']\n",
    "size_data = pd.read_csv(size, sep='\t', names=size_header)\n",
    "for index, eachline in size_data.iterrows():\n",
    "  n_users, n_locations = eachline['users'], eachline['locations']\n",
    "print(\"The numebr of users is\", n_users,\"and the number of locations is\", n_locations)\n",
    "\n",
    "header = ['uid', 'lid', 'freq']\n",
    "train_data = pd.read_csv(train, sep='\t', names=header)\n",
    "test_data = pd.read_csv(test, sep='\t', names=header)\n",
    "\n",
    "geo_header = ['lid', 'lat', 'lng']\n",
    "poi_data = pd.read_csv(geo, sep='\t', names=geo_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwnLMUcudlsJ"
   },
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ew2y3joTkyNf"
   },
   "outputs": [],
   "source": [
    "def read_training_data():\n",
    "  training_matrix = np.zeros((n_users, n_locations))\n",
    "  sparse_training_matrix = sparse.dok_matrix((n_users, n_locations))\n",
    "  for index, row in train_data.iterrows():\n",
    "    uid, lid, freq = row['uid'], row['lid'], row['freq']\n",
    "    uid, lid, freq = int(uid), int(lid), int(freq)\n",
    "    training_matrix[uid, lid] = 1.0\n",
    "    sparse_training_matrix[uid, lid] = freq\n",
    "  return sparse_training_matrix, training_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubiIO-5keMNh"
   },
   "source": [
    "### Load the latitude and longitude of POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0TcJzxUu9hQ"
   },
   "outputs": [],
   "source": [
    "def read_poi_coos():\n",
    "  poi_coos = {}\n",
    "  for index, row in poi_data.iterrows():\n",
    "    lid, lat, lng = row['lid'], row['lat'], row['lng']\n",
    "    lid, lat, lng = int(lid), float(lat), float(lng)\n",
    "    poi_coos[lid] = (lat, lng)\n",
    "  return poi_coos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sojWEvNpefa9"
   },
   "source": [
    "### Load the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMM-Z88f4hd8"
   },
   "source": [
    "A part of dataset should be reserved for testing. Here, we consider 20% of recently available check-ins as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUj12Sn4vJF5"
   },
   "outputs": [],
   "source": [
    "def read_ground_truth():\n",
    "  ground_truth = defaultdict(set)\n",
    "  for index, row in test_data.iterrows():\n",
    "    uid, lid, _ = row['uid'], row['lid'], row['freq']\n",
    "    uid, lid = int(uid), int(lid)\n",
    "    ground_truth[uid].add(lid)\n",
    "  return ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DOPcN2d9fsW"
   },
   "source": [
    "### Intialize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvoTaxNw9lw-"
   },
   "outputs": [],
   "source": [
    "sparse_training_matrix, training_matrix = read_training_data()\n",
    "ground_truth = read_ground_truth()\n",
    "poi_coos = read_poi_coos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZRi3l9UCpKp"
   },
   "source": [
    "## Collaborative Filtering\n",
    "As mentioned earlier, one of the most popular approaches for recommendation is __Collaborative Filtering (CF)__. The user-based approach is suitable for small datasets. When you need scalability, often MF or other model-based approaches perfrom better. Hence, we first consider and implement the user-based CF to recommend POIs. Next, we implement one of the MF-based approaches. Finally, we show the impact of context in RS and integrate one of the most important contextual factors in location recommendation to the MF model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySj5_KG3erQ6"
   },
   "source": [
    "### User-Based Collaborative Filtering [2]\n",
    " A user-based system uses machine-learning algorithms to group all users who have shown to have similar tastes. The system builds neighborhoods of users who have similar profiles, or rating patterns. The recommender system can recommend an item to everyone if a person in his/her neighborhood buys and likes that item. Here, we used __cosine-based similarity__. The cosine-based approach defines the cosine-similarity between two users $x$ and $y$ as:\n",
    " \n",
    " $\\operatorname {sim} (x,y)=\\cos({\\vec {x}},{\\vec {y}})={\\frac {{\\vec {x}}\\cdot {\\vec {y}}}{||{\\vec {x}}||\\times ||{\\vec {y}}||}}={\\frac {\\sum \\limits _{i\\in I_{xy}}r_{x,i}r_{y,i}}{{\\sqrt {\\sum \\limits _{i\\in I_{x}}r_{x,i}^{2}}}{\\sqrt {\\sum \\limits _{i\\in I_{y}}r_{y,i}^{2}}}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMg-KFROzxOL"
   },
   "outputs": [],
   "source": [
    "class UserBasedCF(object):\n",
    "  def __init__(self):\n",
    "    self.rec_score = None\n",
    "    self.epsilon = 1e-9\n",
    "  \n",
    "  \"\"\" This function compute the scores of the users on different POIs based on\n",
    "  the User-based and Cosine similarity \"\"\"\n",
    "  \n",
    "  def pre_compute_rec_scores(self, C):\n",
    "    ctime = time.time()\n",
    "    print(\"Training User-based Collaborative Filtering...\", )\n",
    "\n",
    "    sim = C.dot(C.T)\n",
    "    norms = [norm(C[i]) for i in range(C.shape[0])]\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "      sim[i][i] = 0.0\n",
    "      for j in range(i+1, C.shape[0]):\n",
    "        sim[i][j] = sim[i][j] / ((norms[i] * norms[j]) + self.epsilon)\n",
    "        sim[j][i] = sim[i][j] / ((norms[i] * norms[j]) + self.epsilon)\n",
    "\n",
    "    self.rec_score = sim.dot(C)\n",
    "    print(\"Done. Elapsed time:\", time.time() - ctime, \"s\")\n",
    "\n",
    "  # return the predicted value\n",
    "  def predict(self, i, j):\n",
    "    return self.rec_score[i][j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4v6fASRICSsu"
   },
   "source": [
    "## Evaluation process of recommendation (Precision and Recall)\n",
    "\n",
    "Precision and recall are two commonly used metrics for evaluating the performance of recommender systems. Precision is defined as a fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. You can read more on [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbaKaLlcCXOT"
   },
   "outputs": [],
   "source": [
    "# calculate the precision\n",
    "def precisionk(actual, predicted):\n",
    "  return 1.0 * len(set(actual) & set(predicted)) / len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fhjGJcSoCW36"
   },
   "outputs": [],
   "source": [
    "# calculate the recall\n",
    "def recallk(actual, predicted):\n",
    "  return 1.0 * len(set(actual) & set(predicted)) / len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSbZL4luE7uR"
   },
   "source": [
    "## Store the evaluation values\n",
    "\n",
    "In order to store the results of the experiment we have defined a number of variables (as [list](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEXXk7SvE6po"
   },
   "outputs": [],
   "source": [
    "# precison and recall by user-based CF for each user\n",
    "precision_UB, recall_UB = [], []\n",
    "# precison and recall by Poisson Matrix Factorization Matrix Factorization for each user\n",
    "precision_MF, recall_MF = [], []\n",
    "# precison and recall by MF + Geographical Influence for each user\n",
    "precision_MFG, recall_MFG = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_rhwB3TevOQ"
   },
   "source": [
    "### Recommendation by User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4kTkeEuvWyG"
   },
   "outputs": [],
   "source": [
    "def ub_runer():\n",
    "  top_k = 100\n",
    "  \n",
    "  # remove the last values from pre and rec\n",
    "  del precision_UB[:]\n",
    "  del recall_UB[:]\n",
    "  \n",
    "  U = UserBasedCF()\n",
    "  \n",
    "  # Compute the user-based CF\n",
    "  U.pre_compute_rec_scores(training_matrix)\n",
    "  \n",
    "  all_uids = list(range(n_users))\n",
    "  all_lids = list(range(n_locations))\n",
    "  np.random.shuffle(all_uids)\n",
    "  \n",
    "  # calculate the prediction value for each user on different items\n",
    "  for cnt, uid in enumerate(all_uids):   \n",
    "    if uid in ground_truth:\n",
    "      U_scores = [U.predict(uid, lid)\n",
    "                  if training_matrix[uid, lid] == 0 else -1\n",
    "                  for lid in all_lids]\n",
    "      \n",
    "      U_scores = np.array(U_scores)\n",
    "      \n",
    "      # sort the items based on their prediction value\n",
    "      predicted = list(reversed(U_scores.argsort()))[:top_k]\n",
    "      actual = ground_truth[uid]\n",
    "      \n",
    "      # compute each user's precision and recall\n",
    "      precision_UB.append(precisionk(actual, predicted[:10]))     \n",
    "      recall_UB.append(recallk(actual, predicted[:10]))\n",
    "      \n",
    "  print(\"pre@10:\", np.mean(precision_UB), \"rec@10:\", np.mean(recall_UB))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YbzOmVD2N6Gj",
    "outputId": "3b914dac-fd73-42d3-b328-4e666626b536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training User-based Collaborative Filtering...\n",
      "Done. Elapsed time: 0.21466422080993652 s\n",
      "pre@10: 0.045 rec@10: 0.029128869480040426\n"
     ]
    }
   ],
   "source": [
    "# Now, you can run the user-based CF\n",
    "ub_runer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_UKAy0Q9zJG"
   },
   "source": [
    "## Matrix Factorization (MF)\n",
    "Another technique commonly used for these types of problems is matrix factorization. The idea of this method is to take the original visit count matrix, and then decompose it to two much smaller matrices that approximate the original matrix when multiplied together. You can find more about MF in [quuxlbs blog post](http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/). Here, based on [2], we use a version of matrix factorization called __Poisson Factor Model__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTfDm-NLFwiG"
   },
   "source": [
    "### Matrix Factorization: Poisson Factor Model [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9NEiQBCFw-6"
   },
   "outputs": [],
   "source": [
    "class PoissonFactorModel(object):\n",
    "  def __init__(self, K=30, alpha=20.0, beta=0.2):\n",
    "    self.K = K\n",
    "    self.alpha = alpha\n",
    "    self.beta = beta\n",
    "    self.U, self.L = None, None\n",
    "\n",
    "  def train(self, sparse_check_in_matrix, max_iters=50, learning_rate=1e-4):\n",
    "    ctime = time.time()\n",
    "    print(\"Training PFM...\", )\n",
    "\n",
    "    alpha = self.alpha\n",
    "    beta = self.beta\n",
    "    K = self.K\n",
    "\n",
    "    F = sparse_check_in_matrix\n",
    "    M, N = sparse_check_in_matrix.shape\n",
    "    \n",
    "    # initialize the vectors randomly\n",
    "    U = 0.5 * np.sqrt(np.random.gamma(alpha, beta, (M, K))) / K\n",
    "    L = 0.5 * np.sqrt(np.random.gamma(alpha, beta, (N, K))) / K\n",
    "\n",
    "    F = F.tocoo()\n",
    "    entry_index = list(zip(F.row, F.col))\n",
    "\n",
    "    F = F.tocsr()\n",
    "    F_dok = F.todok()\n",
    "\n",
    "    tau = 10\n",
    "    last_loss = float('Inf')\n",
    "    for iters in range(max_iters):\n",
    "      F_Y = F_dok.copy()\n",
    "      for i, j in entry_index:\n",
    "        F_Y[i, j] = 1.0 * F_dok[i, j] / U[i].dot(L[j]) - 1\n",
    "      F_Y = F_Y.tocsr()\n",
    "\n",
    "      learning_rate_k = learning_rate * tau / (tau + iters)\n",
    "      \n",
    "      # update the user and location (POI) vector\n",
    "      U += learning_rate_k * (F_Y.dot(L) + (alpha - 1) / U - 1 / beta)\n",
    "      L += learning_rate_k * ((F_Y.T).dot(U) + (alpha - 1) / L - 1 / beta)\n",
    "\n",
    "      loss = 0.0\n",
    "      for i, j in entry_index:\n",
    "        loss += (F_dok[i, j] - U[i].dot(L[j]))**2\n",
    "\n",
    "      print('Iteration:', iters,  'loss:', loss)\n",
    "\n",
    "      if loss > last_loss:\n",
    "        print(\"Early termination.\")\n",
    "        break\n",
    "        last_loss = loss\n",
    "\n",
    "      print(\"Done. Elapsed time:\", time.time() - ctime, \"s\")\n",
    "      self.U, self.L = U, L\n",
    "      \n",
    "  # return the predicted value (inner product of vectors)\n",
    "  def predict(self, uid, lid):\n",
    "    return self.U[uid].dot(self.L[lid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4jOnzqBYJ2Z"
   },
   "source": [
    "### Recommendation by the Matrix Factoriztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeV5UG_5YOx9"
   },
   "outputs": [],
   "source": [
    "# This function is similar to the ub_runer() function\n",
    "\n",
    "def mf_runer():\n",
    "  \n",
    "  top_k = 100\n",
    "  \n",
    "  del precision_MF[:]\n",
    "  del recall_MF[:]\n",
    "  \n",
    "  \n",
    "  PFM = PoissonFactorModel(K=30, alpha=20.0, beta=0.2)\n",
    "  PFM.train(sparse_training_matrix, max_iters=10, learning_rate=1e-4)\n",
    "  \n",
    "  all_uids = list(range(n_users))\n",
    "  all_lids = list(range(n_locations))\n",
    "  np.random.shuffle(all_uids)\n",
    "    \n",
    "  for cnt, uid in enumerate(all_uids):\n",
    "    if (int(cnt) != 0 and int(cnt) % 100 == 0):\n",
    "      print(\"Passed\", int(cnt), \"/\", n_users, \"by Precision@10 and Recall@10: \",  np.mean(precision_MF), \"and\", np.mean(recall_MF))\n",
    "    if uid in ground_truth:\n",
    "      overall_scores = [PFM.predict(uid, lid)\n",
    "                        if training_matrix[uid, lid] == 0 else -1\n",
    "                        for lid in all_lids]     \n",
    "      \n",
    "      overall_scores = np.array(overall_scores)\n",
    "\n",
    "      predicted = list(reversed(overall_scores.argsort()))[:top_k]\n",
    "      actual = ground_truth[uid]\n",
    "      \n",
    "      precision_MF.append(precisionk(actual, predicted[:10]))\n",
    "      recall_MF.append(recallk(actual, predicted[:10]))\n",
    "      \n",
    "  print(\">> Finally Precision@10:\", np.mean(precision_MF), \"Recall@10:\", np.mean(recall_MF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "RvjR4qnjYvs8",
    "outputId": "b87a8049-564c-4f27-8778-0b76ab97f63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PFM...\n",
      "Iteration: 0 loss: 153804.6466924741\n",
      "Done. Elapsed time: 0.45594191551208496 s\n",
      "Iteration: 1 loss: 150392.2329277504\n",
      "Done. Elapsed time: 0.8984389305114746 s\n",
      "Iteration: 2 loss: 147679.71908446436\n",
      "Done. Elapsed time: 1.3494558334350586 s\n",
      "Iteration: 3 loss: 145458.23821262922\n",
      "Done. Elapsed time: 1.7642900943756104 s\n",
      "Iteration: 4 loss: 143608.63690096192\n",
      "Done. Elapsed time: 2.1822099685668945 s\n",
      "Iteration: 5 loss: 142051.464637633\n",
      "Done. Elapsed time: 2.699350118637085 s\n",
      "Iteration: 6 loss: 140729.79860856428\n",
      "Done. Elapsed time: 3.17022705078125 s\n",
      "Iteration: 7 loss: 139601.10535289926\n",
      "Done. Elapsed time: 3.600219964981079 s\n",
      "Iteration: 8 loss: 138632.6859252523\n",
      "Done. Elapsed time: 4.003270864486694 s\n",
      "Iteration: 9 loss: 137798.8645074791\n",
      "Done. Elapsed time: 4.416164875030518 s\n",
      ">> Finally Precision@10: 0.027000000000000003 Recall@10: 0.01745983366975592\n"
     ]
    }
   ],
   "source": [
    "mf_runer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PPm-YQPAY2Ep"
   },
   "source": [
    "## Context Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wf2A4gT99h4Q"
   },
   "source": [
    "One of the most important context information for location-based recommendation is geographical information. Geographical (or _spatial_) information allows us to focus recommendations on locations close to the user, keeping our recommendations relevant as a user travels. Users tend to check-in around several centers, where the check-in locations follow a Gaussian distribution at each center. The following code segment shows that a typical user’s check-in behavior appear around a number of centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "colab_type": "code",
    "id": "excCJaGeo9hB",
    "outputId": "8208d552-42e3-41c6-a984-077f6b166cdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <script>L_PREFER_CANVAS=false; L_NO_TOUCH=false; L_DISABLE_3D=false;</script>
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.3.4/dist/leaflet.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.3.4/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
    <meta name="viewport" content="width=device-width,
        initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <style>#map_24ca8e0695b24f6cafc2eaef65635338 {
        position: relative;
        width: 100.0%;
        height: 100.0%;
        left: 0.0%;
        top: 0.0%;
        }
    </style>
</head>
<body>    
    
    <div class="folium-map" id="map_24ca8e0695b24f6cafc2eaef65635338" ></div>
</body>
<script>    
    
    
        var bounds = null;
    

    var map_24ca8e0695b24f6cafc2eaef65635338 = L.map(
        'map_24ca8e0695b24f6cafc2eaef65635338', {
        center: [30.2691029532, -97.7493953705],
        zoom: 5,
        maxBounds: bounds,
        layers: [],
        worldCopyJump: false,
        crs: L.CRS.EPSG3857,
        zoomControl: true,
        });

    
    
    var tile_layer_8271e51c00cd4379a63b1b4c4e791163 = L.tileLayer(
        'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png',
        {
        "attribution": null,
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
    
        var marker_ec65b6b33e72478aad7328188083a211 = L.marker(
            [30.2691029532, -97.7493953705],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_d786e6fe8ac84f6da82eab9b3b2d2f42 = L.marker(
            [30.2557309927, -97.7633857727],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_6f4ce3589f3a44c380f79f92986a83ff = L.marker(
            [30.2679095833, -97.74931241670001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_0ee4a414e7a341c3b35988eb895d7811 = L.marker(
            [30.2811204101, -97.7452111244],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_c246e7d2c9614d92b97722b18f0b3490 = L.marker(
            [30.2448597206, -97.7571630478],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_d2292bb6ce794343afb8d05d8016c89d = L.marker(
            [30.3170157639, -97.7195692062],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_af50ded07b75422f8cd8c68758481552 = L.marker(
            [30.265405690999998, -97.74779140950001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_94cab660ac68420b8899fed6b291e19d = L.marker(
            [30.2464607667, -97.7507881833],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_9fe9c0a8439048b583d129e3a2da8e4a = L.marker(
            [38.9927760833, -94.5952756],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_a22b0b30c34b446ba68f2e55ef671fde = L.marker(
            [39.041052948899996, -94.5947393775],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_b80fff11550a48c5bdaa765a66a07b75 = L.marker(
            [39.0528237667, -94.59031105],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_3a9c0873e6c04280a94ff5f2002b7cbe = L.marker(
            [38.934693546, -94.62979316709999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_53830c6632b94e29bf95b958b0119df1 = L.marker(
            [39.057333533299996, -94.60617950000001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_81e4d31c8b9d49668155ab2964c95fc0 = L.marker(
            [39.0506711667, -94.5980687833],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_eddcd3c11be24951a303541837bd4406 = L.marker(
            [37.7662367387, -96.98147892950001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_5f6b1aa6038b4023a6388ec74d24832c = L.marker(
            [34.185646033299996, -97.1656978333],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_5fefa20ca0754c80b98e2dd6cf6086f3 = L.marker(
            [30.2637747742, -97.77065992360001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_64dd4abb8de24f77b2fbdb8cc3743553 = L.marker(
            [30.2668906357, -97.74568587540001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_e96ba2bc8aea4773953683fdb3c20d89 = L.marker(
            [30.2686964002, -97.7456147969],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_141f009e603f4cbea9d2204cfd311c82 = L.marker(
            [30.310152662199997, -97.7401578426],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_fa6f1dfb779b42d080c08c09dba61586 = L.marker(
            [30.26485415, -97.7438453833],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_c673f6b6b972410b849390630d36c0ec = L.marker(
            [30.2509939667, -97.7489662167],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_04fe4a2eaf704a57a9949f0116440fd4 = L.marker(
            [30.310959277, -97.74269296],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_096d15ff61d2496c90824de9d8041c6d = L.marker(
            [30.31104325, -97.74291515],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_dbb3b0385c534bf681b52904f043bdb0 = L.marker(
            [30.2662396721, -97.74590849879999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_333044af19374efaac7fb14b20784c73 = L.marker(
            [30.270733781599997, -97.7537029982],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_b1e2400c98c94aaeb86e15c0bebc517c = L.marker(
            [30.201557329699998, -97.6671266556],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_05542764813d4b8d96e346d31bf2d597 = L.marker(
            [37.616356064899996, -122.38615036],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_fa8d0e8ffc714dda90951ec82638e590 = L.marker(
            [37.7615082532, -122.42576658700001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_cb0f547f682d4a9e91989a6bd872c576 = L.marker(
            [37.759688872, -122.427177429],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_d62812747b8f495ea1b86d2b9ce977f0 = L.marker(
            [37.78594785, -122.41061780000001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_67d212d83535417f804afd9cb6f7a7f9 = L.marker(
            [37.4191867667, -122.21220151700001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_f0de6eeadaa047c4aa368036339985da = L.marker(
            [37.4157602871, -122.152551413],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_be1896fdcb6c4f028d3588f523f7e4b0 = L.marker(
            [37.7826046833, -122.407608017],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_0b2b134577444913af659e47899416b5 = L.marker(
            [30.2702114098, -97.7497132123],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_f0509aa6a8c343cd926f2dc8d3b60692 = L.marker(
            [30.2493640765, -97.74947047229999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_b9e8d3f0c07a47c5a8535e0f23cf3c10 = L.marker(
            [30.2450661333, -97.75152633329999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_dfad5309ed0f47f3b8595123aba6e708 = L.marker(
            [30.2642977167, -97.73298025],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_e8e4cc7ebf9b41faba5e119fc89f0fd6 = L.marker(
            [30.272031012, -97.75411069389999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_418e1f9b009f40ed9c485fabfadb71a3 = L.marker(
            [30.251046205799998, -97.74932429190001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_ec5626f33eea4682b523da01fb520f0c = L.marker(
            [30.2690658886, -97.7456724644],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_68bd012cbbad4cf6818a0472ae24c874 = L.marker(
            [30.2515346167, -97.7490263167],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_2dcda8319acf4f49838398bae8533f81 = L.marker(
            [30.2510314833, -97.754092],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_383842ab7edf4f1fa7c4f9ef898f9969 = L.marker(
            [39.849501881799995, -104.673871994],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_7cf24c9485fd4b939e15209dfbae02b6 = L.marker(
            [39.2191109667, -106.86401495],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_d6790a2d6b304a379ce2b10f919e106d = L.marker(
            [30.254141466700002, -97.7623172167],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_4a1ce018a8514eda9a9272df3f0f1c87 = L.marker(
            [30.2541434833, -97.7623320667],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_602159d364184328ac93bbb2e9ba5f0c = L.marker(
            [30.3307521333, -97.73175715],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_c6fc6adf2e3f4674b9069fa4e0dfaa55 = L.marker(
            [30.26406815, -97.7672601333],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_916c424ff2d542f294ef955afbea92a2 = L.marker(
            [30.2506754911, -97.7495348454],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_3d52c9a19ab94444aef7612ca8603a91 = L.marker(
            [30.263010098000002, -97.72508164610001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_b44ae46ecdf84fe0b0dcb14169abab11 = L.marker(
            [30.269767796999997, -97.7482661605],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_c6e984bc9846400a9153934a2ffa5f27 = L.marker(
            [30.2627183704, -97.75037169459999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_797054ca18584e1cb4515393a96be427 = L.marker(
            [30.2545781333, -97.769175],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_e0890e1b8d194bd7a8384f74fa65f4f1 = L.marker(
            [30.283552445799998, -97.7225679159],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_15be95af0b53445e9084b414a5325164 = L.marker(
            [30.27055195, -97.7483066333],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_057373b9df00408497bf3ad98d32bebe = L.marker(
            [30.2638859739, -97.7379798889],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_5ce9dbb642384a6b9f78f53e218ac8ae = L.marker(
            [30.26175155, -97.7618140833],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_f2c0f15f60b24005a8c935f2bcc6c79e = L.marker(
            [37.5370606667, -122.327889383],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_7380aa35833f429d98880a5483796bb2 = L.marker(
            [30.2725313677, -97.7536225319],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_5beef944c0cf4d8180ac71f4501b554c = L.marker(
            [30.26280055, -97.7250684167],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_64377952ffef4bb9b53ed11e518ed2a1 = L.marker(
            [38.9989524833, -94.5939345333],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_b08f5440b2ee4bd5a2d106e73f283942 = L.marker(
            [39.0369789909, -94.58718672149999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_da77ddcbd16848ecbe67b134f6c7a193 = L.marker(
            [37.783129592399995, -122.40387439700001],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_e647d866c1e54bf1943dd3c53046d421 = L.marker(
            [37.7864788714, -122.403563261],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_891e775fa0624247bcc8d6f11ff7e383 = L.marker(
            [37.779557700000005, -122.39790915],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_03959c21c2ab49e593c9f7e05a99d0b8 = L.marker(
            [37.7825583, -122.400125433],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_e75533cfed5e4b8eac6f0ffefb4dd524 = L.marker(
            [37.7857173715, -122.399246205],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_2386ca87271248d292c2effd3be8d1d8 = L.marker(
            [37.7881916086, -122.401213646],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_4a15eb5365534aadb076a8eb41f071eb = L.marker(
            [37.7614446392, -122.423958778],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_38d86bc0f40d42c6aa6b5d0b1bc64456 = L.marker(
            [37.7854359476, -122.40394949899999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_74e732db85814ff8829c2091c38c9379 = L.marker(
            [37.7815086, -122.405028233],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_735b12bc025c405db57714f6fabef5ed = L.marker(
            [32.8974616458, -97.04034805299999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_3c3332dd6ce24102b866d97862b7530e = L.marker(
            [30.2624620667, -97.7623715333],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_b08e912e45d44d18a800e69b75e844c3 = L.marker(
            [30.2794862333, -97.7599647667],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_1d2c3b2161c84c47b77e1b64618740d0 = L.marker(
            [30.213861189299998, -97.7694153786],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_1116a238d8764d90aa29f545eb3a1d40 = L.marker(
            [37.7953388902, -122.39372491799999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_f2d14cec509d4634ae91307eb00c1ed5 = L.marker(
            [39.0935326667, -94.5931743],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_dd4e610e7b05440eacf14fd8bfe019d2 = L.marker(
            [39.2974431129, -94.71605300899999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
    
        var marker_f2a8df5742ef440397e20727efb0618d = L.marker(
            [30.248923845, -97.74962604049999],
            {
                icon: new L.Icon.Default()
                }
            ).addTo(map_24ca8e0695b24f6cafc2eaef65635338);
        
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1a10887ac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which user's check-ins distribution want to show?\n",
    "which_user = 0\n",
    "\n",
    "locationlist = []\n",
    "# get the locations that have been checked-in by which_user\n",
    "for user_checkins in range(training_matrix.shape[0]):\n",
    "  if user_checkins == which_user:\n",
    "    locations = training_matrix[user_checkins].nonzero()\n",
    "  break\n",
    "  \n",
    "for locs in locations:\n",
    "  for loc in locs:\n",
    "    lat, lng = poi_coos[loc]\n",
    "    # Make a list with the coordinates of each location\n",
    "    locationlist.append([lat, lng])\n",
    "\n",
    "# Open a map and initialize it with the coordinates\n",
    "map = folium.Map(location=locationlist[0], zoom_start=5)\n",
    "# add to the map all different locations\n",
    "for point in range(0, len(locationlist)):\n",
    "    folium.Marker(locationlist[point]).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iarhCXloPGqQ"
   },
   "source": [
    "### Geographical Information: Multi-center Gaussian Model [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttZljKD5_C_A"
   },
   "source": [
    "Here, we consider the geographical influence based on the idea mentioned above. Then, we fuse the geographical influence into our MF method to show the impact of contextual information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cM_EmZK2YKZ4"
   },
   "source": [
    "#### Find the distance between to location points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZfRRK_JYIH8"
   },
   "outputs": [],
   "source": [
    "# Calculate the distnace between two given POIs or locations\n",
    "def dist(loc1, loc2):\n",
    "    lat1, long1 = loc1.lat, loc1.lng\n",
    "    lat2, long2 = loc2.lat, loc2.lng\n",
    "    if abs(lat1 - lat2) < 1e-6 and abs(long1 - long2) < 1e-6:\n",
    "        return 0.0\n",
    "    degrees_to_radians = math.pi/180.0\n",
    "    phi1 = (90.0 - lat1)*degrees_to_radians\n",
    "    phi2 = (90.0 - lat2)*degrees_to_radians\n",
    "    theta1 = long1*degrees_to_radians\n",
    "    theta2 = long2*degrees_to_radians\n",
    "    cos = (math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2) +\n",
    "           math.cos(phi1)*math.cos(phi2))\n",
    "    arc = math.acos(cos)\n",
    "    earth_radius = 6371\n",
    "    return arc * earth_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JUtm3ohYQTI"
   },
   "source": [
    "#### The geographical approach\n",
    "The final score by Multi-center Gaussian Model is calculated according to the following equation:\n",
    "\n",
    "$P(l|C_u)=\\sum_{c_u=1}^{|C_u|}P(l\\in{C_u})\\frac{f_{c_u}^{\\alpha}}{\\sum_{i\\in{C_u}}f_{i}^{\\alpha}}\\frac{N(l|\\mu_{c_u},\\sum_{c_u})}{\\sum_{i\\in{C_u}}N(l|\\mu_{i},\\sum_{i})}$ (Eq 1. in [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BYmxP8yFYdh"
   },
   "outputs": [],
   "source": [
    "class Location(object):\n",
    "    def __init__(self, id, lat, lng, freq, center=-1):\n",
    "        self.id = id\n",
    "        self.lat = lat\n",
    "        self.lng = lng\n",
    "        self.freq = freq\n",
    "        self.center = center\n",
    "\n",
    "\n",
    "class Center(object):\n",
    "    def __init__(self):\n",
    "        self.locations = []\n",
    "        self.total_freq = 0\n",
    "        self.distribution = None\n",
    "        self.mu = None\n",
    "        self.cov = None\n",
    "        self.lat = None\n",
    "        self.lng = None\n",
    "\n",
    "    def add(self, loc):\n",
    "        self.locations.append(loc)\n",
    "        self.total_freq += loc.freq\n",
    "\n",
    "    def build_gaussian(self):\n",
    "        coo_seq = []\n",
    "        for loc in self.locations:\n",
    "            for _ in range(int(loc.freq)):\n",
    "                coo_seq.append(np.array([loc.lat, loc.lng]))\n",
    "        coo_seq = np.array(coo_seq)\n",
    "        self.mu = np.mean(coo_seq, axis=0)\n",
    "        self.cov = np.cov(coo_seq.T)\n",
    "        self.distribution = multivariate_normal(self.mu, self.cov, allow_singular=True)\n",
    "        self.lat = self.mu[0]\n",
    "        self.lng = self.mu[1]\n",
    "\n",
    "    def pdf(self, x):\n",
    "        return self.distribution.pdf(np.array([x.lat, x.lng]))\n",
    "\n",
    "\n",
    "class MultiGaussianModel(object):\n",
    "    def __init__(self, alpha=0.2, theta=0.02, dmax=15):\n",
    "        self.alpha = alpha\n",
    "        self.theta = theta\n",
    "        self.dmax = dmax\n",
    "        self.poi_coos = None\n",
    "        self.center_list = None\n",
    "\n",
    "    def build_user_check_in_profile(self, sparse_check_in_matrix):\n",
    "        L = defaultdict(list)\n",
    "        for (uid, lid), freq in sparse_check_in_matrix.items():\n",
    "            lat, lng = self.poi_coos[lid]\n",
    "            L[uid].append(Location(lid, lat, lng, freq))\n",
    "        return L\n",
    "\n",
    "    # Find the centers of each users based on the Algorithm 1 in [2]  \n",
    "    def discover_user_centers(self, Lu):\n",
    "        center_min_freq = max(sum([loc.freq for loc in Lu]) * self.theta, 2)\n",
    "        Lu.sort(key=lambda k: k.freq, reverse=True)\n",
    "        center_list = []\n",
    "        center_num = 0\n",
    "        for i in range(len(Lu)):\n",
    "            if Lu[i].center == -1:\n",
    "                center_num += 1\n",
    "                center = Center()\n",
    "                center.add(Lu[i])\n",
    "                Lu[i].center = center_num\n",
    "                for j in range(i+1, len(Lu)):\n",
    "                    if Lu[j].center == -1 and dist(Lu[i], Lu[j]) <= self.dmax:\n",
    "                        Lu[j].center = center_num\n",
    "                        center.add(Lu[j])\n",
    "                if center.total_freq >= center_min_freq:\n",
    "                    center_list.append(center)\n",
    "        return center_list\n",
    "\n",
    "    # calculate the gussain for the related POI at each center\n",
    "    def multi_center_discovering(self, sparse_check_in_matrix, poi_coos):\n",
    "        self.poi_coos = poi_coos\n",
    "        L = self.build_user_check_in_profile(sparse_check_in_matrix)\n",
    "\n",
    "        center_list = {}\n",
    "        for uid in range(len(L)):\n",
    "            center_list[uid] = self.discover_user_centers(L[uid])\n",
    "            for cid in range(len(center_list[uid])):\n",
    "                center_list[uid][cid].build_gaussian()\n",
    "        self.center_list = center_list\n",
    "\n",
    "    # Return the calculated value as the score    \n",
    "    def predict(self, uid, lid):\n",
    "        lat, lng = self.poi_coos[lid]\n",
    "        l = Location(None, lat, lng, None)\n",
    "\n",
    "        prob = 0.0\n",
    "        if uid in self.center_list:\n",
    "            all_center_freq = sum([cid.total_freq**self.alpha for cid in self.center_list[uid]])\n",
    "            all_center_pdf = sum([cid.pdf(l) for cid in self.center_list[uid]])\n",
    "            if not all_center_pdf == 0:\n",
    "                for cu in self.center_list[uid]:\n",
    "                    prob += (\n",
    "                        1.0 / (dist(l, cu) + 1) *\n",
    "                        (cu.total_freq**self.alpha) / all_center_freq *\n",
    "                        cu.pdf(l) / all_center_pdf)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWf3nafNF2QV"
   },
   "source": [
    "### Run the Matrix Factorization with Multi-Center Geographical Model [3] (MFG)\n",
    "For this purpose, the MF method will be fused with the MGM model. The final recommendation score is $P_{ul}=P(F_{ul}).P(l|C_u)$ where $P(F_{ul})$ is acquired from MF and $P(l|C_u)$ is acquired from MGM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jEjVD33iXiw"
   },
   "outputs": [],
   "source": [
    "def mfg_runer():\n",
    "  \n",
    "  top_k = 100\n",
    "  \n",
    "  del precision_MFG[:]\n",
    "  del recall_MFG[:]\n",
    "  \n",
    "  PFM = PoissonFactorModel(K=30, alpha=20.0, beta=0.2)\n",
    "  PFM.train(sparse_training_matrix, max_iters=10, learning_rate=1e-4)\n",
    "  \n",
    "  print(\"Starting Multi-Center Gaussian Model ...\")\n",
    "  MGM = MultiGaussianModel(alpha=0.2, theta=0.02, dmax=15)\n",
    "  MGM.multi_center_discovering(sparse_training_matrix, poi_coos)\n",
    "  print(\"Done Multi-Center Gaussian Model.\")\n",
    "  \n",
    "  all_uids = list(range(n_users))\n",
    "  all_lids = list(range(n_locations))\n",
    "  np.random.shuffle(all_uids)\n",
    "    \n",
    "  for cnt, uid in enumerate(all_uids):\n",
    "    if (int(cnt) != 0 and int(cnt) % 100 == 0):\n",
    "      print(\"Passed\", int(cnt), \"/\", n_users, \"by Precision@10 and Recall@10: \",  np.mean(precision_MFG), \"and\", np.mean(recall_MFG))\n",
    "    if uid in ground_truth:\n",
    "      overall_scores = [PFM.predict(uid, lid) * MGM.predict(uid, lid)\n",
    "                        if training_matrix[uid, lid] == 0 else -1\n",
    "                        for lid in all_lids]     \n",
    "      \n",
    "      overall_scores = np.array(overall_scores)\n",
    "\n",
    "      predicted = list(reversed(overall_scores.argsort()))[:top_k]\n",
    "      actual = ground_truth[uid]\n",
    "      \n",
    "      precision_MFG.append(precisionk(actual, predicted[:10]))\n",
    "      recall_MFG.append(recallk(actual, predicted[:10]))\n",
    "      \n",
    "  print(\">> Finally Precision@10:\", np.mean(precision_MFG), \"Recall@10:\", np.mean(recall_MFG))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "1pQcyEwaifTa",
    "outputId": "b38f4ea5-6c72-4bde-a353-ac0943acd6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PFM...\n",
      "Iteration: 0 loss: 153756.9340099095\n",
      "Done. Elapsed time: 0.42464518547058105 s\n",
      "Iteration: 1 loss: 150345.6249388786\n",
      "Done. Elapsed time: 0.8175218105316162 s\n",
      "Iteration: 2 loss: 147633.7291258644\n",
      "Done. Elapsed time: 1.2159099578857422 s\n",
      "Iteration: 3 loss: 145412.73761428182\n",
      "Done. Elapsed time: 1.640434980392456 s\n",
      "Iteration: 4 loss: 143563.5865373208\n",
      "Done. Elapsed time: 2.0435080528259277 s\n",
      "Iteration: 5 loss: 142006.85345896395\n",
      "Done. Elapsed time: 2.4830880165100098 s\n",
      "Iteration: 6 loss: 140685.62480364006\n",
      "Done. Elapsed time: 2.8502211570739746 s\n",
      "Iteration: 7 loss: 139557.36970378723\n",
      "Done. Elapsed time: 3.253411054611206 s\n",
      "Iteration: 8 loss: 138589.38933528026\n",
      "Done. Elapsed time: 3.678169012069702 s\n",
      "Iteration: 9 loss: 137756.00711654316\n",
      "Done. Elapsed time: 4.069010972976685 s\n",
      "Starting Multi-Center Gaussian Model ...\n",
      "Done Multi-Center Gaussian Model.\n",
      ">> Finally Precision@10: 0.042 Recall@10: 0.0269395778054627\n"
     ]
    }
   ],
   "source": [
    "mfg_runer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xh4GBlODFf0l"
   },
   "source": [
    "## Expriment Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "SnTpHs2SCizH",
    "outputId": "8012bdec-9702-41e9-9587-5cf98dd2de81"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to plot\n",
    "n_groups = 3\n",
    "means_precision = (np.mean(precision_UB), np.mean(precision_MF), np.mean(precision_MFG))\n",
    "means_recall = (np.mean(recall_UB), np.mean(recall_MF), np.mean(recall_MFG))\n",
    "\n",
    " \n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.25\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, means_precision, bar_width,\n",
    "alpha=opacity,\n",
    "label='Precision')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, means_recall, bar_width,\n",
    "alpha=opacity,\n",
    "label='Recall')\n",
    " \n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Precision and Recall')\n",
    "plt.title('Results')\n",
    "plt.xticks(index + 0.1, ('UB', 'MF', 'MFG'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ft3GCk70A5Y5"
   },
   "source": [
    "### Significance of the results\n",
    "The bar chart above compares the result of recommendation based on a User-Based (UB) approach, Matrix Factorization (MF), and Matrix Factorization with geographical influence (MFG). You already see some differences in the bar charts above. However, to show whether the difference achieved in the results is significant or not (i.e. there is a significant difference between the means of two distributions) you can use the _t-Test_. For this purpose, you need to run _t-Test_ for each result based on each metric. You can find more details in the following link and see how to use _t-Test_ in python with Scipy: [t-Test in Scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XKM8x0e9vZW"
   },
   "source": [
    "### Conclusion\n",
    "As you can see in the plot that the UB method is outperforming other methods. Not achieving better performance form MF-based methods can be due to the inadequate size of the dataset used. Here, the size of the dataset is very small (100 users). The _user-based_ approach uses all of the users' and items' information.  When the number of users and items grow, the MF approaches will show their performance gain better. Furthermore, you can see that MFG is outperforming MF. This shows the impact of context information in modeling users' behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNt6JUTTY0xt"
   },
   "source": [
    "## Acknowledgement\n",
    "For implemenation we got some information and inspiration of the codes that provided by the following paper:  \n",
    "__ [1] Liu, Yiding, et al. \"An experimental evaluation of point-of-interest recommendation in location-based social networks.\" in VLDB, 2017__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJUOWKG0UdTI"
   },
   "source": [
    "## References\n",
    "\n",
    "__ [2] Ye, Mao, et al. \"Exploiting geographical influence for collaborative point-of-interest recommendation\" in SIGIR, 2011.__  \n",
    "__ [3] Cheng, Chen, et al. \"Fused matrix factorization with geographical and social influence in location-based social networks\", in AAAI, 2012.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "POI Recommender Systems.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
