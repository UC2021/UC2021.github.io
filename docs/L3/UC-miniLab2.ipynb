{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to best fill a Pandas dataframe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjuYH5N4NZJY",
        "colab_type": "text"
      },
      "source": [
        "# **Urban Computing - (mini) Lab 2**\n",
        "\n",
        "This lab provides tips for using Pandas dataframe more efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF83x5tjh5Yh",
        "colab_type": "text"
      },
      "source": [
        "# How best to fill a Pandas dataframe?\n",
        "\n",
        "When working with Pandas dataframes, you of course sometimes have to add some rows with data to it, either to fill an empty dataframe or add to an existing one. But are there worse and better ways to do it? Using the techniques introduced in Lab 1, we can investigate this quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuqvO44Kh6B0",
        "colab_type": "text"
      },
      "source": [
        "Get some data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMIxr_Xch8RA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "106584f7-7c47-41ae-c011-b1090569115c"
      },
      "source": [
        "# !pip install foursquare\n",
        "\n",
        "import pandas as pd\n",
        "import foursquare as fsq\n",
        "pd.options.display.width = 1000\n",
        "pd.options.display.max_columns = 0\n",
        "\n",
        "# Please copy paste your client_id and client_secret from your web foursquare-app\n",
        "cl_id='your client ID'\n",
        "cl_sec='your client secret'\n",
        "\n",
        "# Construct the client object\n",
        "client = fsq.Foursquare(client_id=cl_id, client_secret=cl_sec)\n",
        "\n",
        "# Use your Client and request data from foursquare\n",
        "data = client.venues.search(params={'ll': '52.159536, 4.491366', 'query': 'bar', \n",
        "                                    'intent': 'browse', 'radius':3000, 'limit':50})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting foursquare\n",
            "  Downloading https://files.pythonhosted.org/packages/16/c7/d51ecf7e06a75741a61ff752e5e010db8794ec0af01da98f42db7ab64ffe/foursquare-1%212020.1.30-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.1 in /usr/local/lib/python3.6/dist-packages (from foursquare) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from foursquare) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1->foursquare) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1->foursquare) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1->foursquare) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1->foursquare) (3.0.4)\n",
            "Installing collected packages: foursquare\n",
            "Successfully installed foursquare-1!2020.1.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIk5zVqYh_fG",
        "colab_type": "text"
      },
      "source": [
        "## First attempt:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0bp4-15iEb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a function\n",
        "def venue_scraper_v1(data):\n",
        "    df = pd.DataFrame(columns = ['name', 'latitude', 'longitude', 'distance', 'address'])\n",
        "    \n",
        "    for i in data['venues']:\n",
        "        df.append({\n",
        "            'name': i['name'],\n",
        "            'latitude': i['location']['lat'],\n",
        "            'longitude': i['location']['lng'],\n",
        "            'distance': i['location']['distance'],\n",
        "            'address': i['location']['formattedAddress'][0]\n",
        "        }, ignore_index=True)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsBkijfmiU8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1e37eecd-cce2-465f-dcb1-ecf0c386a883"
      },
      "source": [
        "print(venue_scraper_v1(data).head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [name, latitude, longitude, distance, address]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvjI2n-ZiXjW",
        "colab_type": "text"
      },
      "source": [
        "Why didn't it work? Because `df.append()` returns a new dataframe!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-v95jgPickG",
        "colab_type": "text"
      },
      "source": [
        "## Second attempt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybjDkVX_ih5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a function\n",
        "def venue_scraper_v2(data):\n",
        "    df = pd.DataFrame(columns = ['name', 'latitude', 'longitude', 'distance', 'address'])\n",
        "    \n",
        "    for i in data['venues']:\n",
        "        df = df.append({\n",
        "            'name': i['name'],\n",
        "            'latitude': i['location']['lat'],\n",
        "            'longitude': i['location']['lng'],\n",
        "            'distance': i['location']['distance'],\n",
        "            'address': i['location']['formattedAddress'][0]\n",
        "        }, ignore_index=True)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FvoKBePiko6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "c9db1346-caba-4d8d-f53d-560b7ec6fb5d"
      },
      "source": [
        "print(venue_scraper_v2(data).head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   name   latitude  longitude distance            address\n",
            "0    Cosmo Blow Dry Bar  52.159146   4.490836       56  Aalmarkt 22 (V&D)\n",
            "1  Bar-Dancing De Kroon  52.163177   4.494783      467     Langegracht 65\n",
            "2          M Noodle Bar  52.162870   4.484963      573     Beestenmarkt 4\n",
            "3           Rooftop Bar  52.164953   4.488021      644          Nederland\n",
            "4    Bar Bistro Raphael  52.159177   4.491167       42      Nieuwe Rijn 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EACQOxjim5n",
        "colab_type": "text"
      },
      "source": [
        "Okay, it works, but is it the best way? We're generating a new dataframe for each row we're appending. That doesn't sound efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8LbMdXbixUB",
        "colab_type": "text"
      },
      "source": [
        "## Third attempt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49hmvQKci4Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a function\n",
        "def venue_scraper_v3(data):\n",
        "\n",
        "    # Initialize a dictionary of lists\n",
        "    d = {'name' : [], 'lat':[], 'lng': [], 'dist': [], 'address': [], 'genre': []}\n",
        "    \n",
        "    # Fill the dictionary from the API results\n",
        "    for i in range(len(data['venues'])):\n",
        "        d['name'].append(data['venues'][i]['name'])\n",
        "        d['lat'].append(data['venues'][i]['location']['lat'])\n",
        "        d['lng'].append(data['venues'][i]['location']['lng'])\n",
        "        d['dist'].append(data['venues'][i]['location']['distance'])\n",
        "        if 'address' in data['venues'][i]['location'].keys():\n",
        "            d['address'].append(data['venues'][i]['location']['address'])\n",
        "        else:\n",
        "            d['address'].append('NA')\n",
        "        if data['venues'][i]['categories'] != []:\n",
        "            d['genre'].append(data['venues'][i]['categories'][0]['pluralName'])\n",
        "        else:\n",
        "            d['genre'].append('NA')\n",
        "            \n",
        "    # Construct a dataframe from the dictionary-of-lists\n",
        "    df = pd.DataFrame.from_dict(d)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXYSB9CGi44M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "79156bd1-98db-4725-87fb-a1ab915bc1e0"
      },
      "source": [
        "print(venue_scraper_v3(data).head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   name        lat  ...         address                 genre\n",
            "0    Cosmo Blow Dry Bar  52.159146  ...     Aalmarkt 22  Salons / Barbershops\n",
            "1  Bar-Dancing De Kroon  52.163177  ...  Langegracht 65              Gay Bars\n",
            "2          M Noodle Bar  52.162870  ...  Beestenmarkt 4         Noodle Houses\n",
            "3           Rooftop Bar  52.164953  ...              NA                    NA\n",
            "4    Bar Bistro Raphael  52.159177  ...   Nieuwe Rijn 1                  Bars\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID_0j1ixjexd",
        "colab_type": "text"
      },
      "source": [
        "## Fourth variation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewVHiE-Gjcqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a function\n",
        "def venue_scraper_v4(data):\n",
        "    df = pd.DataFrame(columns = ['name', 'latitude', 'longitude', 'distance', 'address'])\n",
        "    \n",
        "    batch = []\n",
        "    for i in data['venues']:\n",
        "        batch.append(pd.Series([\n",
        "            i['name'], \n",
        "            i['location']['lat'],\n",
        "            i['location']['lng'],\n",
        "            i['location']['distance'],\n",
        "            i['location']['formattedAddress'][0]\n",
        "        ], index=df.columns))\n",
        "    df = df.append(batch, ignore_index=True)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPSF03YYjhqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "74e85555-a63d-4175-b0ad-a7fe9aa45b37"
      },
      "source": [
        "print(venue_scraper_v4(data).head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   name   latitude  longitude distance            address\n",
            "0    Cosmo Blow Dry Bar  52.159146   4.490836       56  Aalmarkt 22 (V&D)\n",
            "1  Bar-Dancing De Kroon  52.163177   4.494783      467     Langegracht 65\n",
            "2          M Noodle Bar  52.162870   4.484963      573     Beestenmarkt 4\n",
            "3           Rooftop Bar  52.164953   4.488021      644          Nederland\n",
            "4    Bar Bistro Raphael  52.159177   4.491167       42      Nieuwe Rijn 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN3vemGwjldO",
        "colab_type": "text"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSPjVd4tjn-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a434341-6a81-4bcb-e877-2065ced5a8f1"
      },
      "source": [
        "%timeit venue_scraper_v2(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 208 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2I_PHbNjry0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "846ef2bf-c664-4378-cd2b-3a16ae25d7c5"
      },
      "source": [
        "%timeit venue_scraper_v3(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.03 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUdZDI4Ljw2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e493488-82ef-41f2-be91-e2e34f4c71c9"
      },
      "source": [
        "%timeit venue_scraper_v4(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 11.8 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FygJs1ttj1aH",
        "colab_type": "text"
      },
      "source": [
        "Remember: 1 ms = 1000 Âµs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8rn1Sarj3UP",
        "colab_type": "text"
      },
      "source": [
        "## What's the underlying idea?\n",
        "Pandas uses Numpy arrays under the hood, which are very fast because every cell in the array is right next to the previous one. So reading from one cell to the next is a very simple and fast operation.\n",
        "\n",
        "Pandas is in column-major order, which means that the data is stored in column-arrays in memory. So to add a row, you'd have to add a cell to the end of each column. And check if there's actually room there in memory to make the columns longer, because the cells of the column have to remain contiguous. \n",
        "\n",
        "Doing that again and again for each row is not efficient. So the *ideal* approach is to create a dataframe from all your data as a set of columns. If that's not an option, for example because you're handling some kind of incoming data stream, then you can still achieve a speedup by adding multiple rows as a batch.\n",
        "\n",
        "(Of course, in practice, very often you're getting your data from a CSV because it doesn't make sense to download it again and again from an API if you're fine-tuning code that's not actually related to connecting to the API. And Pandas has excellent CSV import abilities to efficiently load big files.)"
      ]
    }
  ]
}